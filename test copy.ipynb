{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "crateri",
   "display_name": "crateri",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/sirbastiano/anaconda3/envs/crateri/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# External libraries\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import pandas as pd\n",
    "import astropy\n",
    "import scipy\n",
    "from filterpy.kalman import KalmanFilter \n",
    "from filterpy.common import Q_discrete_white_noise\n",
    "from scipy.linalg import block_diag\n",
    "from astropy import units as u\n",
    "from poliastro.bodies import Earth, Mars, Sun, Moon\n",
    "from poliastro.twobody import Orbit\n",
    "from poliastro.plotting import OrbitPlotter2D\n",
    "from poliastro.plotting import OrbitPlotter3D\n",
    "from sklearn import linear_model, datasets\n",
    "import glob\n",
    "# Own Libraries\n",
    "from utility.utils import *\n",
    "from KalmanFilter.kf import *\n",
    "from Detect.detector import *\n",
    "from Match.pair import *\n",
    "from Match.icp import *\n",
    "\n",
    "%matplotlib tk\n",
    "style.use('seaborn-paper')\n",
    "\n",
    "global km2px, deg2km, px2km, deg2px\n",
    "\n",
    "print('\\r')\n",
    "print('Done!')"
   ]
  },
  {
   "source": [
    "# Image Detection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Detection Time:4.74\n",
      "\n",
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "\n",
      "\n",
      "Total craters founded:9\n",
      "Number of total combinations:504\n",
      "Computational time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "# Loading All Images:\n",
    "dict = load_all_images(dt=10)\n",
    "idx = 11  # Loading image n. idx+1 ...\n",
    "# Img:\n",
    "filename = dict[str(idx+1)]\n",
    "img=cv2.imread(filename)\n",
    "# Detection:\n",
    "t1 = time.time()\n",
    "craters_det = detect(img)\n",
    "# Removing minor craters:\n",
    "craters_det = craters_det[craters_det[:,2] > 15]\n",
    "t2 = time.time()\n",
    "print(f'Detection Time:{t2-t1:.2f}\\n')\n",
    "# Pandas DataFrame:\n",
    "df_craters_det = sort_mat(craters_det)\n",
    "# Find all triplets:\n",
    "t1 = time.time()\n",
    "triplets = find_all_triplets(craters_det)\n",
    "triplets_det= pd.DataFrame(triplets, columns=['Angle1','Angle2','Angle3','des1','des2','des3','x1','y1','r1','x2','y2','r2','x3','y3','r3'])\n",
    "triplets_det.shape\n",
    "t2 = time.time()\n",
    "print('\\n')\n",
    "print(f'Total craters founded:{craters_det.shape[0]}')\n",
    "print(f'Number of total combinations:{triplets_det.shape[0]}\\nComputational time: {t2-t1:.2f} s')"
   ]
  },
  {
   "source": [
    "# DataFrame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "Total craters catalogued:172\n",
      "Number of total combinations:4912830\n",
      "Computational time: 72.14 s\n"
     ]
    }
   ],
   "source": [
    "# Opening Database:\n",
    "# DB = pd.read_csv('DATA/H_L_combined.csv')\n",
    "DB = pd.read_csv('DATA/lunar_crater_database_robbins_2018.csv')\n",
    "\n",
    "# Filtering DATABASE:\n",
    "MULTIPLAYER = 2\n",
    "span = 3.29/2   *MULTIPLAYER # TODO: Aggiustare l'immagine di catalogo a grandezza effettiva!\n",
    "lat_bounds=[-span, span]\n",
    "get_lon = float(filename.split('_')[-1].split('jpg')[0][:-2])\n",
    "lon_bounds=[get_lon-span,get_lon+span]\n",
    "# craters_cat = CatalogSearch(DB, lat_bounds, lon_bounds, CAT_NAME='COMBINED')\n",
    "craters_cat = CatalogSearch(DB, lat_bounds, lon_bounds, CAT_NAME='ROBBINS')\n",
    "\n",
    "# FIND TRIPLETS:\n",
    "if craters_cat is not None:\n",
    "    km2deg = 1/deg2km\n",
    "    craters_cat = craters_cat[(craters_cat.Diam < 40)&(craters_cat.Diam > 3.5)]\n",
    "    craters_cat['Diam']*=0.5*km2deg # km --- > deg\n",
    "\n",
    "    craters_cat_m = np.array(craters_cat)\n",
    "    t1 = time.time()\n",
    "    triplets_cat_m = find_all_triplets(craters_cat_m)\n",
    "    triplets_cat = pd.DataFrame(triplets_cat_m, columns=['Angle1','Angle2','Angle3','des1','des2','des3','lon1','lat1', 'r1','lon2','lat2','r2','lon3','lat3','r3'])\n",
    "    triplets_cat['r1'] *= deg2km\n",
    "    triplets_cat['r2'] *= deg2km\n",
    "    triplets_cat['r3'] *= deg2km\n",
    "    t2 = time.time()\n",
    "    print(f'Total craters catalogued:{craters_cat.shape[0]+1}')\n",
    "    print(f'Number of total combinations:{triplets_cat.shape[0]}\\nComputational time: {t2-t1:.2f} s')\n",
    "else:\n",
    "    print('No craters in cat!')"
   ]
  },
  {
   "source": [
    "# Plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img1\n",
    "plt.figure(dpi=200, tight_layout=True)\n",
    "cp1 = deepcopy(img)\n",
    "img_det = img_plus_crts(img, craters_det)\n",
    "plt.subplot(122)\n",
    "plt.xticks([0,848/2,848],[f'{lon_bounds[0]:.2f}°',f'{(lon_bounds[1]+lon_bounds[0])/2:.2f}°',f'{lon_bounds[1]:.2f}°'])\n",
    "plt.yticks([0,848/2,848],[f'{lat_bounds[0]:.2f}°',f'{(lat_bounds[1]+lat_bounds[0])/2:.2f}°',f'{lat_bounds[1]:.2f}°'])\n",
    "plt.imshow(img_det)\n",
    "plt.xlabel('LON')\n",
    "plt.ylabel('LAT')\n",
    "plt.show()\n",
    "\n",
    "# FIG.2\n",
    "cp1 = deepcopy(img)\n",
    "# DB = pd.read_csv('DATA/lunar_crater_database_robbins_2018.csv')\n",
    "# DB = pd.read_csv('DATA/H_L_combined.csv')\n",
    "# df = CatalogSearch(DB, lat_bounds, lon_bounds, CAT_NAME='COMBINED')\n",
    "df = CatalogSearch(DB, lat_bounds, lon_bounds, CAT_NAME='ROBBINS')\n",
    "df = df[df.Diam > 3.5]\n",
    "image_with_craters = draw_craters_on_image(df,  lon_bounds, lat_bounds, cp1, u=None)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(image_with_craters)\n",
    "plt.xticks([0,850/2,850],[f'{lon_bounds[0]:.2f}°',f'{(lon_bounds[1]+lon_bounds[0])/2:.2f}°',f'{lon_bounds[1]:.2f}°'])\n",
    "plt.yticks([0,850/2, 850],[f'{lat_bounds[0]:.2f}°',f'{(lat_bounds[1]+lat_bounds[0])/2:.2f}°',f'{lat_bounds[1]:.2f}°'])\n",
    "plt.xlabel('LON')\n",
    "plt.ylabel('LAT')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Inner Join Merging"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mode:inverse\nComputational time: 5.63 s\nPossible list Combinations: 84\n"
     ]
    }
   ],
   "source": [
    "tol1 = 7.\n",
    "\n",
    "t1 = time.time()\n",
    "QUERY1 = triplets_cat\n",
    "QUERY2 = triplets_det\n",
    "QUERY1 = dropduplicates(QUERY1)\n",
    "QUERY2 = dropduplicates(QUERY2) \n",
    "\n",
    "if QUERY1.shape[0]<QUERY2.shape[0]:\n",
    "    mode = 'natural'\n",
    "    joins, items = inner_join(QUERY1, QUERY2, tol1)\n",
    "else:\n",
    "    mode = 'inverse'\n",
    "    joins, items = inner_join(QUERY2, QUERY1, tol1)\n",
    "print(f'Mode:{ mode}')\n",
    "t2 = time.time()\n",
    "print(f'Computational time: {t2-t1:.2f} s\\nPossible list Combinations: {len(items)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Computational time: 0.58 s\nPossible list Combinations: 84\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "tol2 = 1.\n",
    "S, iss = [], []\n",
    "for i in range(len(joins)):\n",
    "    join = joins[i]\n",
    "    des1, des2, des3 = items[i].des1, items[i].des2, items[i].des3\n",
    "    s=join[ (abs(join.des1 - des1) < tol2) & (abs(join.des2 - des2) < tol2) & (abs(join.des3 - des3) < tol2)\\\n",
    "          | (abs(join.des1 - des2) < tol2) & (abs(join.des2 - des3) < tol2) & (abs(join.des3 - des1) < tol2)\\\n",
    "          | (abs(join.des1 - des3) < tol2) & (abs(join.des2 - des1) < tol2) & (abs(join.des3 - des2) < tol2)]\n",
    "\n",
    "    if s.shape[0] > 0:\n",
    "        S.append(s)\n",
    "        iss.append(items[i])\n",
    "t2 = time.time()\n",
    "print(f'Computational time: {t2-t1:.2f} s\\nPossible list Combinations: {len(S)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 7\n",
      "5 3\n",
      "32 23\n",
      "51 22\n",
      "56 10\n",
      "56 38\n",
      "57 3\n",
      "62 33\n"
     ]
    }
   ],
   "source": [
    "# FIND TRUE COMBINATIONS:\n",
    "CAMx, CAMy = ( (lon_bounds[0] + lon_bounds[1]) / 2, (lat_bounds[0] + lat_bounds[1]) / 2) # Location Absolute\n",
    "\n",
    "Is, Js = [], []\n",
    "for I in range(len(iss)):\n",
    "    row1 = iss[I]\n",
    "    for J in range(S[I].shape[0]):\n",
    "        if check_sol(I,J, 0.1, mode, S, iss) & check_sol2(I,J, 0.14, mode, S, iss, CAMx, CAMy): # TODO: Aggiungere checksol3: confronto crts\n",
    "                Is.append(I)\n",
    "                Js.append(J)\n",
    "                print(I,J)\n",
    "Is = np.array(Is)\n",
    "Js = np.array(Js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "# PLOT PAIRS:\n",
    "for index in range(len(Is)):\n",
    "    I = Is[index]\n",
    "    J = Js[index]\n",
    "    plot_sol(I,J, mode, S, iss, lon_bounds, lat_bounds, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Height: 50.06          px2deg: 0.00389\n"
     ]
    }
   ],
   "source": [
    "if len(Js)!=0:    \n",
    "    \n",
    "    H, px2deg = H_estimation(Is, Js, mode, S, iss, CAMx, CAMy)\n",
    "    print(f'Height: {H:.2f}          px2deg: {px2deg:.5f}')\n",
    "\n",
    "else: print('Association was not possible...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LON: -141.990       LAT:0.007\n"
     ]
    }
   ],
   "source": [
    "if len(Js)!=0: \n",
    "    LON, LAT = [], []\n",
    "    for s in range(len(Is)):\n",
    "        i, j = Is[s], Js[s]\n",
    "        A,B,B_a = find_ABBa(i,j,mode, S, iss, CAMx, CAMy)\n",
    "\n",
    "        Lon, Lat = LL_estimation(A, B, B_a, px2deg)\n",
    "        LON.append(Lon)\n",
    "        LAT.append(Lat)\n",
    "    if len(LON)>3:\n",
    "        LON_m = np.mean(filter_quartile(LON))\n",
    "        LAT_m = np.mean(filter_quartile(LAT))\n",
    "    else:\n",
    "        LON_m = np.mean(LON)\n",
    "        LAT_m = np.mean(LAT)\n",
    "\n",
    "    print(f'LON: {LON_m:.3f}       LAT:{LAT_m:.3f}')\n",
    "else: print('Association was not possible...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error (km)| H: 0.06Km    Lon:0.14Km    Lat:-0.20Km\n"
     ]
    }
   ],
   "source": [
    "dt = 10\n",
    "df = pd.read_csv(f'DATA/ephemeris sat/inclination zero/{dt} step size.csv', header=3, sep=';') \n",
    "real_Latitudes, real_Longitudes, real_Altitudes = df['Lat (deg)'], df['Lon (deg)'], df['Alt (km)']\n",
    "real_Vxs,real_Vys,real_Vzs = df['x (km/sec)'], df['y (km/sec)'],df['z (km/sec)']\n",
    "\n",
    "real_X, real_Y, real_Z = [], [], []\n",
    "for i in range(len(df)):\n",
    "    altitude = real_Altitudes[i]\n",
    "    latitude = real_Latitudes[i]\n",
    "    longitude = real_Longitudes[i]\n",
    "    x, y, z = spherical2cartesian(altitude, latitude, longitude)\n",
    "    real_X.append(x)\n",
    "    real_Y.append(y)\n",
    "    real_Z.append(z)\n",
    "real_X, real_Y, real_Z = np.array(real_X),np.array(real_Y),np.array(real_Z)\n",
    "\n",
    "\n",
    "Error = []\n",
    "if len(Js)!=0: \n",
    "    TRUE_POS = np.array([real_Longitudes[idx], real_Latitudes[idx]])\n",
    "    # print(TRUE_POS)\n",
    "    D = TRUE_POS - np.array([LON_m,LAT_m])\n",
    "    ERROR_LL = D*deg2km\n",
    "    Error.append(H-50)\n",
    "    Error.append(ERROR_LL[0])\n",
    "    Error.append(ERROR_LL[1])\n",
    "    print(f'Error (km)| H: {Error[0]:.2f}Km    Lon:{Error[1]:.2f}Km    Lat:{Error[2]:.2f}Km')\n",
    "else: print('Association was not possible...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}