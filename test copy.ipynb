{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "crateri",
   "display_name": "crateri",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Import\n",
    "Importo tutte le librerie e le funzioni scritte."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/sirbastiano/anaconda3/envs/crateri/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# External libraries\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import pandas as pd\n",
    "import astropy\n",
    "import scipy\n",
    "from filterpy.kalman import KalmanFilter \n",
    "from filterpy.common import Q_discrete_white_noise\n",
    "from scipy.linalg import block_diag\n",
    "from astropy import units as u\n",
    "from poliastro.bodies import Earth, Mars, Sun, Moon\n",
    "from poliastro.twobody import Orbit\n",
    "from poliastro.plotting import OrbitPlotter2D\n",
    "from poliastro.plotting import OrbitPlotter3D\n",
    "from sklearn import linear_model, datasets\n",
    "import glob\n",
    "# Own Libraries\n",
    "from utility.utils import *\n",
    "from KalmanFilter.kf import *\n",
    "from Detect.detector import *\n",
    "from Match.pair import *\n",
    "from Match.icp import *\n",
    "\n",
    "%matplotlib tk\n",
    "style.use('seaborn-paper')\n",
    "\n",
    "global km2px, deg2km, px2km, deg2px\n",
    "\n",
    "print('\\r')\n",
    "print('Done!')"
   ]
  },
  {
   "source": [
    "# Crater Detection e Triplet Detected\n",
    "In questa sezione, vengono individuati i crateri. Noti questi ultimi all'interno della immagine (x,y,r) vengono individuate tutte le triplette date dalla combinazione di tre differenti crateri, in maniera simile a uno star tracker. Le funzioni di creazione triplette sono state riscritte in linguaggio macchina per poter consentire una maggiore velocità, anche milioni di combinazioni possono essere processate in pochi minuti. Da queste triplette vengono estratte le invarianti geoemetriche (seguendo la bibliografia di Hannok (NASA)): le invarianti geoemetriche non dipendono dall'altitudine del satellite o dal suo orientamento e pertanto possono essere utilizzate per stimare la posizione del satellite in maniera assoluta. Le invarianti geoemetriche utilizzate sono gli angoli interni e il rapporto tra i diametri e la distanza del centroide della tripletta. Di seguito il codice riporta anche le tempistiche per una area di scan di 100kmx100km.\n",
    "\n",
    "-Detection Time: è il tempo che impiega la rete neurale a individuare i crateri nella immagine.\n",
    "\n",
    "-Computatinal Time: è il tempo che impiega l'algoritmo in linguaggio macchina per trovare le triplette."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Detection Time:4.57\n",
      "\n",
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "\n",
      "\n",
      "Total craters founded:7\n",
      "Number of total combinations:210\n",
      "Computational time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "# Loading All Images:\n",
    "dict = load_all_images(dt=10)\n",
    "idx = 40  # Loading image n. idx+1 ...\n",
    "# Img:\n",
    "filename = dict[str(idx+1)]\n",
    "img=cv2.imread(filename)\n",
    "# Detection:\n",
    "t1 = time.time()\n",
    "craters_det = detect(img)\n",
    "# Removing minor craters:\n",
    "craters_det = craters_det[craters_det[:,2] > 15]\n",
    "t2 = time.time()\n",
    "print(f'Detection Time:{t2-t1:.2f}\\n')\n",
    "# Pandas DataFrame:\n",
    "df_craters_det = sort_mat(craters_det)\n",
    "# Find all triplets:\n",
    "t1 = time.time()\n",
    "triplets = find_all_triplets(craters_det)\n",
    "triplets_det= pd.DataFrame(triplets, columns=['Angle1','Angle2','Angle3','des1','des2','des3','x1','y1','r1','x2','y2','r2','x3','y3','r3'])\n",
    "triplets_det.shape\n",
    "t2 = time.time()\n",
    "print('\\n')\n",
    "print(f'Total craters founded:{craters_det.shape[0]}')\n",
    "print(f'Number of total combinations:{triplets_det.shape[0]}\\nComputational time: {t2-t1:.2f} s')"
   ]
  },
  {
   "source": [
    "# DataFrame\n",
    "In questa sezione vengono stimate con il medesimo algoritmo le triplette nel catalogo. Ho provato a utilizzare due database di crateri, H+L (Lo stesso di LunaNet) e Robbins. Il Robbins è risultato migliore in quanto H+L risultava manchevole in molte zone: abbiamo bisogno di almeno 3 crateri per stimare la posizione. In questo caso effettuo la scan di un area di 200kmx200km. I tempi computazionali dipendono sostanzialmente da quanti crateri ci sono nell'area. \n",
    "\n",
    "TODO: In questo momento la funzione ricerca tutte le possibili triplette nell'area senza considerare la footprint del sensore, è questo che aumenta in maniera esponenziale il tempo computazionale. Sto ancora lavorando all'idea di un catalogo completo per il completo Lost-In-Space, al momento mi risulta impossibile: troppe le combinazioni, troppo il costo computazionale. Forse avendo una indicazione \"di massima\" sull'altezza si potrebbe trovare soluzione al problema. Ho anche provato a utilizzare SQL per la gestione del database ma i tempi non sono migliorati."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "Total craters catalogued:75\n",
      "Number of total combinations:388944\n",
      "Computational time: 5.90 s\n"
     ]
    }
   ],
   "source": [
    "# Opening Database:\n",
    "# DB = pd.read_csv('DATA/H_L_combined.csv')\n",
    "DB = pd.read_csv('DATA/lunar_crater_database_robbins_2018.csv')\n",
    "\n",
    "# Filtering DATABASE:\n",
    "MULTIPLAYER = 2\n",
    "span = 3.29/2   *MULTIPLAYER # TODO: Aggiustare l'immagine di catalogo a grandezza effettiva!\n",
    "lat_bounds=[-span, span]\n",
    "get_lon = float(filename.split('_')[-1].split('jpg')[0][:-2])\n",
    "lon_bounds=[get_lon-span,get_lon+span]\n",
    "# craters_cat = CatalogSearch(DB, lat_bounds, lon_bounds, CAT_NAME='COMBINED')\n",
    "craters_cat = CatalogSearch(DB, lat_bounds, lon_bounds, CAT_NAME='ROBBINS')\n",
    "\n",
    "# FIND TRIPLETS:\n",
    "if craters_cat is not None:\n",
    "    km2deg = 1/deg2km\n",
    "    craters_cat = craters_cat[(craters_cat.Diam < 40)&(craters_cat.Diam > 3.5)]\n",
    "    craters_cat['Diam']*=0.5*km2deg # km --- > deg\n",
    "\n",
    "    craters_cat_m = np.array(craters_cat)\n",
    "    t1 = time.time()\n",
    "    triplets_cat_m = find_all_triplets(craters_cat_m)\n",
    "    triplets_cat = pd.DataFrame(triplets_cat_m, columns=['Angle1','Angle2','Angle3','des1','des2','des3','lon1','lat1', 'r1','lon2','lat2','r2','lon3','lat3','r3'])\n",
    "    triplets_cat['r1'] *= deg2km\n",
    "    triplets_cat['r2'] *= deg2km\n",
    "    triplets_cat['r3'] *= deg2km\n",
    "    t2 = time.time()\n",
    "    print(f'Total craters catalogued:{craters_cat.shape[0]+1}')\n",
    "    print(f'Number of total combinations:{triplets_cat.shape[0]}\\nComputational time: {t2-t1:.2f} s')\n",
    "else:\n",
    "    print('No craters in cat!')"
   ]
  },
  {
   "source": [
    "# Plot\n",
    "In rosso i crateri individuati dalla rete. In blu quelli catalogati nel Robbins."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img1\n",
    "plt.figure(dpi=200, tight_layout=True)\n",
    "cp1 = deepcopy(img)\n",
    "img_det = img_plus_crts(img, craters_det)\n",
    "plt.subplot(122)\n",
    "plt.xticks([0,848/2,848],[f'{lon_bounds[0]:.2f}°',f'{(lon_bounds[1]+lon_bounds[0])/2:.2f}°',f'{lon_bounds[1]:.2f}°'])\n",
    "plt.yticks([0,848/2,848],[f'{lat_bounds[0]:.2f}°',f'{(lat_bounds[1]+lat_bounds[0])/2:.2f}°',f'{lat_bounds[1]:.2f}°'])\n",
    "plt.imshow(img_det)\n",
    "plt.xlabel('LON')\n",
    "plt.ylabel('LAT')\n",
    "plt.show()\n",
    "\n",
    "# FIG.2\n",
    "cp1 = deepcopy(img)\n",
    "# DB = pd.read_csv('DATA/lunar_crater_database_robbins_2018.csv')\n",
    "# DB = pd.read_csv('DATA/H_L_combined.csv')\n",
    "# df = CatalogSearch(DB, lat_bounds, lon_bounds, CAT_NAME='COMBINED')\n",
    "df = CatalogSearch(DB, lat_bounds, lon_bounds, CAT_NAME='ROBBINS')\n",
    "df = df[df.Diam > 3.5]\n",
    "image_with_craters = draw_craters_on_image(df,  lon_bounds, lat_bounds, cp1, u=None)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(image_with_craters)\n",
    "plt.xticks([0,850/2,850],[f'{lon_bounds[0]:.2f}°',f'{(lon_bounds[1]+lon_bounds[0])/2:.2f}°',f'{lon_bounds[1]:.2f}°'])\n",
    "plt.yticks([0,850/2, 850],[f'{lat_bounds[0]:.2f}°',f'{(lat_bounds[1]+lat_bounds[0])/2:.2f}°',f'{lat_bounds[1]:.2f}°'])\n",
    "plt.xlabel('LON')\n",
    "plt.ylabel('LAT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Img = cv2.imread('figure/Figure_1A.png')\n",
    "plt.figure(dpi=250)\n",
    "plt.imshow(Img)\n",
    "plt.axis(False)\n",
    "plt.ylim([800,250])\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Inner Join Merging\n",
    "A questo punto viene fatto il cosidetto \"inner join\" merging di due dataframe: vengono cercate in pratica le triplette comuni. Essendo le misure affette da errori, ho introdotti differenti gradi di tolleranza a seconda delle invarianti geometriche. \n",
    "\n",
    "- tol1: esprime la tolleranza rispetto agli angoli interni.\n",
    "- tol2: esprime la tolleranza rispetto ai rapporti  diametro/distanza centroide.\n",
    "- tol3 & tol4: sono tolleranza rispetto alla rotazione e rapporti di grandezza relativa tra coppie di triplette."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mode:inverse\nComputational time: 0.53 s\nPossible list Combinations: 35\n"
     ]
    }
   ],
   "source": [
    "tol1 = 7.\n",
    "\n",
    "t1 = time.time()\n",
    "QUERY1 = triplets_cat\n",
    "QUERY2 = triplets_det\n",
    "QUERY1 = dropduplicates(QUERY1)\n",
    "QUERY2 = dropduplicates(QUERY2) \n",
    "\n",
    "if QUERY1.shape[0]<QUERY2.shape[0]:\n",
    "    mode = 'natural'\n",
    "    joins, items = inner_join(QUERY1, QUERY2, tol1)\n",
    "else:\n",
    "    mode = 'inverse'\n",
    "    joins, items = inner_join(QUERY2, QUERY1, tol1)\n",
    "print(f'Mode:{ mode}')\n",
    "t2 = time.time()\n",
    "print(f'Computational time: {t2-t1:.2f} s\\nPossible list Combinations: {len(items)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Computational time: 0.13 s\nPossible list Combinations: 34\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "tol2 = 1.\n",
    "S, iss = [], []\n",
    "for i in range(len(joins)):\n",
    "    join = joins[i]\n",
    "    des1, des2, des3 = items[i].des1, items[i].des2, items[i].des3\n",
    "    s=join[ (abs(join.des1 - des1) < tol2) & (abs(join.des2 - des2) < tol2) & (abs(join.des3 - des3) < tol2)\\\n",
    "          | (abs(join.des1 - des2) < tol2) & (abs(join.des2 - des3) < tol2) & (abs(join.des3 - des1) < tol2)\\\n",
    "          | (abs(join.des1 - des3) < tol2) & (abs(join.des2 - des1) < tol2) & (abs(join.des3 - des2) < tol2)]\n",
    "\n",
    "    if s.shape[0] > 0:\n",
    "        S.append(s)\n",
    "        iss.append(items[i])\n",
    "t2 = time.time()\n",
    "print(f'Computational time: {t2-t1:.2f} s\\nPossible list Combinations: {len(S)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5 3\n",
      "6 0\n",
      "9 1\n",
      "10 4\n",
      "12 0\n",
      "25 0\n",
      "28 0\n",
      "31 0\n"
     ]
    }
   ],
   "source": [
    "# FIND TRUE COMBINATIONS:\n",
    "CAMx, CAMy = ( (lon_bounds[0] + lon_bounds[1]) / 2, (lat_bounds[0] + lat_bounds[1]) / 2) # Location Absolute\n",
    "\n",
    "Is, Js = [], []\n",
    "for I in range(len(iss)):\n",
    "    row1 = iss[I]\n",
    "    for J in range(S[I].shape[0]):\n",
    "        if check_sol(I,J, 0.1, mode, S, iss) & check_sol2(I,J, 0.14, mode, S, iss, CAMx, CAMy): # TODO: Aggiungere checksol3: confronto crts\n",
    "                Is.append(I)\n",
    "                Js.append(J)\n",
    "                print(I,J)\n",
    "Is = np.array(Is)\n",
    "Js = np.array(Js)"
   ]
  },
  {
   "source": [
    "# Plotting delle triplette Accoppiate:\n",
    "Ne riporto tre a titolo di esempio.\n",
    "- Sx: quella identificata nel catalogo.\n",
    "- Dx: quella sulla immagine. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "# PLOT PAIRS:\n",
    "for index in range(len(Is)):\n",
    "    I = Is[index]\n",
    "    J = Js[index]\n",
    "    plot_sol(I,J, mode, S, iss, lon_bounds, lat_bounds, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=200)\n",
    "img = cv2.imread(f'figure/Figure_1.png')\n",
    "plt.axis(False)\n",
    "plt.ylim([500,100])\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "img = cv2.imread(f'figure/Figure_2.png')\n",
    "plt.axis(False)\n",
    "plt.ylim([500,100])\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "img = cv2.imread(f'figure/Figure_3.png')\n",
    "plt.axis(False)\n",
    "plt.ylim([500,100])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Stima della Posizione.\n",
    "Avendo a questo punto individuato un set di triplette a le corrispondenti longitudini latitudini, non è stato difficile scrivere una formulazione che permette il calcolo dell'Altezza e Latitudine, Longitudine. La formulazione che ho utilizzato è di tipo lineare, ho semplicemente fatto corrispondere a tot numero di pixel con tot gradi di LAT/LON (le distanze tra crateri). Nota questa relazione da pixel a gradi (px2deg) e noto il numero di pixel del sensore è facile stimare l'altitudine. In maniera simile ricavo LON e LAT relaziondole al centro della immagine.\n",
    "\n",
    "- Ultima nota: ho filtrato gli outlier con metodo dell'interquantile dal 45 al 55, di modo che le associazioni sbagliate (che a volte sono presenti per il fatto che le misure non sono comunque affette da errori) vengano non considerate ai fini di calcolo di ALT,LON,LAT."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Height: 51.79          px2deg: 0.00402\n"
     ]
    }
   ],
   "source": [
    "if len(Js)!=0:    \n",
    "    \n",
    "    H, px2deg = H_estimation(Is, Js, mode, S, iss, CAMx, CAMy)\n",
    "    print(f'Height: {H:.2f}          px2deg: {px2deg:.5f}')\n",
    "\n",
    "else: print('Association was not possible...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LON: -126.623       LAT:0.003\n"
     ]
    }
   ],
   "source": [
    "if len(Js)!=0: \n",
    "    LON, LAT = [], []\n",
    "    for s in range(len(Is)):\n",
    "        i, j = Is[s], Js[s]\n",
    "        A,B,B_a = find_ABBa(i,j,mode, S, iss, CAMx, CAMy)\n",
    "\n",
    "        Lon, Lat = LL_estimation(A, B, B_a, px2deg)\n",
    "        LON.append(Lon)\n",
    "        LAT.append(Lat)\n",
    "    if len(LON)>3:\n",
    "        LON_m = np.mean(filter_quartile(LON))\n",
    "        LAT_m = np.mean(filter_quartile(LAT))\n",
    "    else:\n",
    "        LON_m = np.mean(LON)\n",
    "        LAT_m = np.mean(LAT)\n",
    "\n",
    "    print(f'LON: {LON_m:.3f}       LAT:{LAT_m:.3f}')\n",
    "else: print('Association was not possible...')"
   ]
  },
  {
   "source": [
    "# L'errore\n",
    "Il conseguente errore sulla stima di posizione. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error (km)| H: 1.79Km    Lon:-0.02Km    Lat:-0.10Km\n"
     ]
    }
   ],
   "source": [
    "dt = 10\n",
    "df = pd.read_csv(f'DATA/ephemeris sat/inclination zero/{dt} step size.csv', header=3, sep=';') \n",
    "real_Latitudes, real_Longitudes, real_Altitudes = df['Lat (deg)'], df['Lon (deg)'], df['Alt (km)']\n",
    "real_Vxs,real_Vys,real_Vzs = df['x (km/sec)'], df['y (km/sec)'],df['z (km/sec)']\n",
    "\n",
    "real_X, real_Y, real_Z = [], [], []\n",
    "for i in range(len(df)):\n",
    "    altitude = real_Altitudes[i]\n",
    "    latitude = real_Latitudes[i]\n",
    "    longitude = real_Longitudes[i]\n",
    "    x, y, z = spherical2cartesian(altitude, latitude, longitude)\n",
    "    real_X.append(x)\n",
    "    real_Y.append(y)\n",
    "    real_Z.append(z)\n",
    "real_X, real_Y, real_Z = np.array(real_X),np.array(real_Y),np.array(real_Z)\n",
    "\n",
    "\n",
    "Error = []\n",
    "if len(Js)!=0: \n",
    "    TRUE_POS = np.array([real_Longitudes[idx], real_Latitudes[idx]])\n",
    "    # print(TRUE_POS)\n",
    "    D = TRUE_POS - np.array([LON_m,LAT_m])\n",
    "    ERROR_LL = D*deg2km\n",
    "    Error.append(H-50)\n",
    "    Error.append(ERROR_LL[0])\n",
    "    Error.append(ERROR_LL[1])\n",
    "    print(f'Error (km)| H: {Error[0]:.2f}Km    Lon:{Error[1]:.2f}Km    Lat:{Error[2]:.2f}Km')\n",
    "else: print('Association was not possible...')"
   ]
  },
  {
   "source": [
    "# Valori Globali \n",
    "Ripeto questa procedura per le prime 60 immagini distanziate di 10sec su una scan area di 100kmx100km. Ottenendo i seguenti risultati."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = cv2.imread('AltitudeError_d=100.jpg') \n",
    "B = cv2.imread('LongitudeError_d=100.jpg') \n",
    "C = cv2.imread('LatitudeError_d=100.jpg') \n",
    "plt.figure(dpi=300)\n",
    "plt.axis(False)\n",
    "plt.imshow(A)\n",
    "plt.figure(dpi=300)\n",
    "plt.axis(False)\n",
    "plt.imshow(B)\n",
    "plt.figure(dpi=300)\n",
    "plt.axis(False)\n",
    "plt.imshow(C)\n",
    "plt.show()\n"
   ]
  }
 ]
}